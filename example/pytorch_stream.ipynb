{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52afa009",
   "metadata": {},
   "source": [
    "# Demonstration of histomics_stream\n",
    "\n",
    "Click to open in [[GitHub](https://github.com/DigitalSlideArchive/HistomicsStream/tree/master/example/pytorch.ipynb)] [[Google Colab](https://colab.research.google.com/github/DigitalSlideArchive/HistomicsStream/blob/master/example/pytorch_stream.ipynb)]\n",
    "\n",
    "The `histomics_stream` Python package sits at the start of any machine learning workflow that is built on the PyTorch machine learning library.  The package is responsible for efficient access to the input image data that will be used to fit a new machine learning model or will be used to predict regions of interest in novel inputs using an already learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf42bd",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you are running this notebook on Google Colab or another system where `histomics_stream` and its dependencies are not yet installed then they can be installed with the following commands.  Note that image readers in addition to openslide are also supported by using, e.g., `large_image[openslide,ometiff,openjpeg,bioformats]` on the below pip install command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ee19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histomics_stream and its dependencies\n",
    "!apt update\n",
    "!apt install -y python3-openslide openslide-tools\n",
    "!pip install 'large_image[openslide]' --find-links https://girder.github.io/large_image_wheels\n",
    "!pip install histomics_stream\n",
    "\n",
    "# Get other packages used in this notebook\n",
    "# N.B. itkwidgets works with jupyter<=3.0.0\n",
    "!apt install libcudnn8 libcudnn8-dev\n",
    "!pip install histomics_detect pooch itkwidgets\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-matplotlib jupyterlab-datawidgets itkwidgets\n",
    "\n",
    "print(\n",
    "    \"\\nNOTE!: On Google Colab you may need to choose 'Runtime->Restart runtime' for these updates to take effect.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8f7db",
   "metadata": {},
   "source": [
    "## Fetching and creating the test data\n",
    "This notebook has demonstrations that use the files `TCGA-AN-A0G0-01Z-00-DX1.svs` (365 MB) and `TCGA-AN-A0G0-01Z-00-DX1.mask.png` (4 kB),  The pooch commands will fetch them if they are not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "\n",
    "# download whole slide image\n",
    "wsi_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.svs\",\n",
    "    url=\"https://northwestern.box.com/shared/static/qelyzb45bigg6sqyumtj8kt2vwxztpzm\",\n",
    "    known_hash=\"d046f952759ff6987374786768fc588740eef1e54e4e295a684f3bd356c8528f\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {wsi_path}\")\n",
    "\n",
    "# download binary mask image\n",
    "mask_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.mask.png\",\n",
    "    url=\"https://northwestern.box.com/shared/static/2q13q2r83avqjz9glrpt3s3nop6uhi2i\",\n",
    "    known_hash=\"bb657ead9fd3b8284db6ecc1ca8a1efa57a0e9fd73d2ea63ce6053fbd3d65171\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68668b27",
   "metadata": {},
   "source": [
    "## Creating a study for use with histomics_stream\n",
    "\n",
    "We describe the input and desired parameters using standard Python lists and dictionaries.  Here we give a high-level configuration; selection of tiles is done subsequently.\n",
    "\n",
    "N.B.: __*all*__ values that are number of pixels are based upon the `target_magnification` that is supplied to `FindResolutionForSlide`.  This includes pixel sizes of a slide, chunk, or tile and it includes the pixel coordinates for a chunk or tile.  It applies whether the numbers are supplied to histomics_stream or returned by histomics_stream.  However, if the `magnification_source` is not `exact` the `returned_magnification` may not equal the `target_magnification`; to get the number of pixels that is relevant for the `returned_magnification`, typically these numbers of pixels are multiplied by the ratio `returned_magnification / target_magnification`.  In particular, the *pixel size of the returned tiles* will be the requested size times this ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import histomics_stream as hs\n",
    "import histomics_stream.pytorch\n",
    "import torch\n",
    "\n",
    "# Create a study and insert study-wide information\n",
    "my_study0 = {\"version\": \"version-1\"}\n",
    "my_study0[\"number_pixel_rows_for_tile\"] = 256\n",
    "my_study0[\"number_pixel_columns_for_tile\"] = 256\n",
    "my_slides = my_study0[\"slides\"] = {}\n",
    "\n",
    "# Add a slide to the study, including slide-wide information with it.\n",
    "my_slide0 = my_slides[\"Slide_0\"] = {}\n",
    "my_slide0[\"filename\"] = wsi_path\n",
    "my_slide0[\"slide_name\"] = \"TCGA-AN-A0G0-01Z-00-DX1\"\n",
    "my_slide0[\"slide_group\"] = \"Group 3\"\n",
    "my_slide0[\"number_pixel_rows_for_chunk\"] = 2048\n",
    "my_slide0[\"number_pixel_columns_for_chunk\"] = 2048\n",
    "\n",
    "# For each slide, find the appropriate resolution given the target_magnification and\n",
    "# magnification_tolerance.  In this example, we use the same parameters for each slide,\n",
    "# but this is not required generally.\n",
    "find_resolution_for_slide = hs.configure.FindResolutionForSlide(\n",
    "    my_study0, target_magnification=20, magnification_source=\"native\"\n",
    ")\n",
    "for slide in my_study0[\"slides\"].values():\n",
    "    find_resolution_for_slide(slide)\n",
    "print(f\"my_study0 = {my_study0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d428686",
   "metadata": {},
   "source": [
    "## Tile selection\n",
    "\n",
    "We are going to demonstrate several approaches to choosing tiles.  Each approach will start with its own copy of the `my_study0` that we have built so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f184408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask without a mask\n",
    "my_study_tiles_by_grid = copy.deepcopy(my_study0)\n",
    "tiles_by_grid = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid,\n",
    "    number_pixel_overlap_rows_for_tile=32,\n",
    "    number_pixel_overlap_columns_for_tile=32,\n",
    "    randomly_select=5,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid[\"slides\"].values():\n",
    "    tiles_by_grid(slide)\n",
    "print(f\"my_study_tiles_by_grid = {my_study_tiles_by_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_tiles_by_grid_and_mask = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid_and_mask,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    randomly_select=10,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid_and_mask[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(f\"my_study_tiles_by_grid_and_mask = {my_study_tiles_by_grid_and_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c16959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByList\n",
    "my_study_tiles_by_list = copy.deepcopy(my_study0)\n",
    "tiles_by_list = hs.configure.TilesByList(\n",
    "    my_study_tiles_by_list,\n",
    "    randomly_select=5,\n",
    "    tiles_dictionary=my_study_tiles_by_grid[\"slides\"][\"Slide_0\"][\"tiles\"],\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_list[\"slides\"].values():\n",
    "    tiles_by_list(slide)\n",
    "print(f\"my_study_tiles_by_list = {my_study_tiles_by_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesRandomly\n",
    "my_study_tiles_randomly = copy.deepcopy(my_study0)\n",
    "tiles_randomly = hs.configure.TilesRandomly(my_study_tiles_randomly, randomly_select=10)\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_randomly[\"slides\"].values():\n",
    "    tiles_randomly(slide)\n",
    "print(f\"my_study_tiles_randomly = {my_study_tiles_randomly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733607e",
   "metadata": {},
   "source": [
    "## Creating a Dataset\n",
    "\n",
    "We request tiles indicated by the mask and create a Dataset that has the image data for these tiles as well as associated parameters for each tile, such as its location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13156e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_of_tiles = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_of_tiles,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    mask_threshold=0.5,\n",
    "    randomly_select=100,\n",
    ")\n",
    "for slide in my_study_of_tiles[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(\"Finished selecting tiles.\")\n",
    "\n",
    "create_pytorch_dataloader = hs.pytorch.CreateTorchDataloader()\n",
    "tiles = create_pytorch_dataloader(my_study_of_tiles)\n",
    "print(\"Finished with CreateTorchDataloader\")\n",
    "print(f\"{type(tiles)=}\")\n",
    "print(f\"{type(iter(tiles))=}\")\n",
    "print(f\"{dir(tiles)=}\")\n",
    "print(f\"{type(tiles.dataset)=}\")\n",
    "print(f\"{type(tiles.dataset.__iter__())=}\")\n",
    "tile_iter = iter(tiles)\n",
    "tile = next(tile_iter)\n",
    "print(f\"{type(tile)=}\")\n",
    "print(f\"{len(tile)=}\")\n",
    "print(f\"{type(tile[0])=}\")\n",
    "print(f\"{type(tile[1])=}\")\n",
    "# print(f\"{tile=}\")\n",
    "# print(f\"... with tile shape = {tiles.take(1).get_single_element()[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d5b93",
   "metadata": {},
   "source": [
    "## Fetch a model for prediction\n",
    "\n",
    "We fetch a model (840 MB compressed, 1.3 GB decompressed) that we will use to make predictions.\n",
    "\n",
    "Because each element of our Dataset is a tuple `(rgb_image_data, dictionary_of_annotation)`, a typical model that accepts only the former as its input needs to be wrapped.\n",
    "\n",
    "Note that this model assumes that the tiles/images are not batched, with the understanding that if there is enough memory to do batching then one should instead choose a larger tile size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3cf69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download trained model.\n",
    "model_path = pooch.retrieve(\n",
    "    fname=\"tcga_brca_model\",\n",
    "    url=\"https://northwestern.box.com/shared/static/4g6idrqlpvgxnsktz8pym5386njyvyb6\",\n",
    "    known_hash=\"b5b5444cc8874d17811a89261abeafd9b9603e7891a8b2a98d8f13e2846a6689\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"model\",\n",
    "    processor=pooch.Unzip(),\n",
    ")\n",
    "model_path = os.path.split(model_path[0])[0]\n",
    "print(f\"Have {model_path}.\")\n",
    "\n",
    "# restore keras model\n",
    "from histomics_detect.models import FasterRCNN\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path, custom_objects={\"FasterRCNN\": FasterRCNN}\n",
    ")\n",
    "\n",
    "# Each element of the `tiles` tensorflow Dataset is a (rgb_image_data, dictionary_of_annotation) pair.\n",
    "# Wrap the unwrapped_model so that it knows to use the image.\n",
    "class WrappedModel(tf.keras.Model):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super(WrappedModel, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, element):\n",
    "        return (self.model(element[0]), element[1])\n",
    "\n",
    "\n",
    "unwrapped_model = model\n",
    "model = WrappedModel(unwrapped_model)\n",
    "print(\"Model built and wrapped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1530c",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starting predictions\")\n",
    "start_time = time.time()\n",
    "# This model assumes that the tiles are not batched.  Do not use, e.g., tiles.batch(32).\n",
    "predictions = model.predict(tiles)\n",
    "end_time = time.time()\n",
    "number_of_inputs = len([0 for tile in tiles])\n",
    "number_of_predictions = predictions[0].shape[0]\n",
    "print(\n",
    "    f\"Made {number_of_predictions} predictions for {number_of_inputs} tiles in {end_time - start_time} s.\"\n",
    ")\n",
    "print(f\"Average of {(end_time - start_time) / number_of_inputs} s per tile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29db04d",
   "metadata": {},
   "source": [
    "## Look at internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f522902",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_element = tiles.take(1).get_single_element()\n",
    "my_pair = my_element[0]\n",
    "my_target = my_element[1]\n",
    "my_weight = my_element[2]\n",
    "my_image = my_pair[0]\n",
    "my_annotation = my_pair[1]\n",
    "\n",
    "print(f\"   type(my_element) = {type(my_element)}\")\n",
    "print(f\"    len(my_element) = {len(my_element)}\")\n",
    "print(f\"      type(my_pair) = {type(my_pair)}\")\n",
    "print(f\"       len(my_pair) = {len(my_pair)}\")\n",
    "print(f\"    type(my_target) = {type(my_target)}\")\n",
    "print(f\"    type(my_weight) = {type(my_weight)}\")\n",
    "print(f\"     type(my_image) = {type(my_image)}\")\n",
    "print(f\"     my_image.shape = {my_image.shape}\")\n",
    "print(f\"type(my_annotation) = {type(my_annotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadfd84",
   "metadata": {},
   "source": [
    "## Display a tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk, itkwidgets\n",
    "\n",
    "itkwidgets.view(itk.image_from_array(my_image.numpy(), is_vector=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histomics_stream",
   "language": "python",
   "name": "histomics_stream"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
