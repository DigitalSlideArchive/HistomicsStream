{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29bedd9",
   "metadata": {},
   "source": [
    "# Demonstration of histomics_stream\n",
    "\n",
    "Click to open in [[GitHub](https://github.com/DigitalSlideArchive/histomics_stream/tree/master/example/tensorflow_stream.ipynb)] [[Google Colab](https://colab.research.google.com/github/DigitalSlideArchive/histomics_stream/blob/master/example/tensorflow_stream.ipynb)]\n",
    "\n",
    "The `histomics_stream` Python package sits at the start of any machine learning workflow that is built on the TensorFlow machine learning library.  The package is responsible for efficient access to the input image data that will be used to fit a new machine learning model or will be used to predict regions of interest in novel inputs using an already learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92649bc7",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you are running this notebook on Google Colab or another system where `histomics_stream` and its dependencies are not yet installed then they can be installed with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf991e19-7647-4a43-9d6b-8b46f64651a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install -y python3-openslide openslide-tools\n",
    "\n",
    "!pip install histomics_stream 'large_image[openslide,ometiff,openjpeg,bioformats]' pooch --find-links https://girder.github.io/large_image_wheels\n",
    "\n",
    "import sys\n",
    "!pip install /tf/notebooks/histomics_detect\n",
    "sys.path.append(\"/tf/notebooks/histomics_detect/\")\n",
    "\n",
    "print(\n",
    "    \"\\nNOTE!: On Google Colab you may need to choose 'Runtime->Restart runtime' for these updates to take effect.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b637125",
   "metadata": {},
   "source": [
    "## Fetching and creating the test data\n",
    "This notebook has demonstrations that use the files `TCGA-AN-A0G0-01Z-00-DX1.svs` (365 MB) and `TCGA-AN-A0G0-01Z-00-DX1.mask.png` (4 kB),  The pooch commands will fetch them if they are not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "\n",
    "# download whole slide image\n",
    "wsi_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.svs\",\n",
    "    url=\"https://northwestern.box.com/shared/static/qelyzb45bigg6sqyumtj8kt2vwxztpzm\",\n",
    "    known_hash=\"d046f952759ff6987374786768fc588740eef1e54e4e295a684f3bd356c8528f\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {wsi_path}\")\n",
    "\n",
    "# download binary mask image\n",
    "mask_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.mask.png\",\n",
    "    url=\"https://northwestern.box.com/shared/static/2q13q2r83avqjz9glrpt3s3nop6uhi2i\",\n",
    "    known_hash=\"bb657ead9fd3b8284db6ecc1ca8a1efa57a0e9fd73d2ea63ce6053fbd3d65171\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468174d3",
   "metadata": {},
   "source": [
    "## Creating a study for use with histomics_stream\n",
    "\n",
    "We describe the input and desired parameters using standard Python lists and dictionaries.  Here we give a high-level configuration; selection of tiles is done subsequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import histomics_stream as hs\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a study and insert study-wide information\n",
    "my_study0 = {\"version\": \"version-1\"}\n",
    "my_study0[\"number_pixel_rows_for_tile\"] = 256\n",
    "my_study0[\"number_pixel_columns_for_tile\"] = 256\n",
    "my_slides = my_study0[\"slides\"] = {}\n",
    "\n",
    "# Add a slide to the study, including slide-wide information with it.\n",
    "my_slide0 = my_slides[\"Slide_0\"] = {}\n",
    "my_slide0[\"filename\"] = wsi_path\n",
    "my_slide0[\"slide_name\"] = \"TCGA-AN-A0G0-01Z-00-DX1\"\n",
    "my_slide0[\"slide_group\"] = \"Group 3\"\n",
    "my_slide0[\"number_pixel_rows_for_chunk\"] = 2048\n",
    "my_slide0[\"number_pixel_columns_for_chunk\"] = 2048\n",
    "\n",
    "# For each slide, find the appropriate resolution given the target_magnification and\n",
    "# magnification_tolerance.  In this example, we use the same parameters for each slide,\n",
    "# but this is not required generally.\n",
    "find_resolution_for_slide = hs.configure.FindResolutionForSlide(\n",
    "    my_study0, target_magnification=20, magnification_source=\"native\"\n",
    ")\n",
    "for slide in my_study0[\"slides\"].values():\n",
    "    find_resolution_for_slide(slide)\n",
    "print(f\"my_study0 = {my_study0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bcd69",
   "metadata": {},
   "source": [
    "## Tile selection\n",
    "\n",
    "We are going to demonstrate several approaches to choosing tiles.  Each approach will start with its own copy of the `my_study0` that we have built so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask without a mask\n",
    "my_study_tiles_by_grid = copy.deepcopy(my_study0)\n",
    "tiles_by_grid = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid,\n",
    "    number_pixel_overlap_rows_for_tile=32,\n",
    "    number_pixel_overlap_columns_for_tile=32,\n",
    "    randomly_select=5,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid[\"slides\"].values():\n",
    "    tiles_by_grid(slide)\n",
    "print(f\"my_study_tiles_by_grid = {my_study_tiles_by_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8276190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_tiles_by_grid_and_mask = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid_and_mask,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    randomly_select=10,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid_and_mask[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(f\"my_study_tiles_by_grid_and_mask = {my_study_tiles_by_grid_and_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByList\n",
    "my_study_tiles_by_list = copy.deepcopy(my_study0)\n",
    "tiles_by_list = hs.configure.TilesByList(\n",
    "    my_study_tiles_by_list,\n",
    "    randomly_select=5,\n",
    "    tiles_dictionary=my_study_tiles_by_grid[\"slides\"][\"Slide_0\"][\"tiles\"],\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_list[\"slides\"].values():\n",
    "    tiles_by_list(slide)\n",
    "print(f\"my_study_tiles_by_list = {my_study_tiles_by_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesRandomly\n",
    "my_study_tiles_randomly = copy.deepcopy(my_study0)\n",
    "tiles_randomly = hs.configure.TilesRandomly(my_study_tiles_randomly, randomly_select=10)\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_randomly[\"slides\"].values():\n",
    "    tiles_randomly(slide)\n",
    "print(f\"my_study_tiles_randomly = {my_study_tiles_randomly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36bb8c",
   "metadata": {},
   "source": [
    "## Creating a TensorFlow Dataset\n",
    "\n",
    "We request tiles indicated by the mask and create a tensorflow Dataset that has the image data for these tiles as well as associated parameters for each tile, such as its location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ce1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_of_tiles = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_of_tiles,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    mask_threshold=0.5,\n",
    "    randomly_select=100,\n",
    ")\n",
    "for slide in my_study_of_tiles[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(\"Finished selecting tiles.\")\n",
    "\n",
    "create_tensorflow_dataset = hs.tensorflow.CreateTensorFlowDataset()\n",
    "tiles = create_tensorflow_dataset(my_study_of_tiles)\n",
    "print(\"Finished with CreateTensorFlowDataset\")\n",
    "print(f\"... with tile shape = {tiles.take(1).get_single_element()[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81ffe2",
   "metadata": {},
   "source": [
    "## Fetch a model for prediction\n",
    "\n",
    "We fetch a model (840 MB compressed, 1.3 GB decompressed) that we will use to make predictions.\n",
    "\n",
    "Because each element of our Dataset is a tuple `(rgb_image_data, dictionary_of_annotation)`, a typical model that accepts only the former as its input needs to be wrapped.\n",
    "\n",
    "Note that this model assumes that the tiles/images are not batched, with the understanding that if there is enough memory to do batching then one should instead choose a larger tile size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download trained model.\n",
    "model_path = pooch.retrieve(\n",
    "    fname=\"tcga_brca_model\",\n",
    "    url=\"https://northwestern.box.com/shared/static/4g6idrqlpvgxnsktz8pym5386njyvyb6\",\n",
    "    known_hash=\"b5b5444cc8874d17811a89261abeafd9b9603e7891a8b2a98d8f13e2846a6689\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"model\",\n",
    "    processor=pooch.Unzip(),\n",
    ")\n",
    "model_path = os.path.split(model_path[0])[0]\n",
    "print(f\"Have {model_path}.\")\n",
    "\n",
    "# restore keras model\n",
    "from histomics_detect.models import FasterRCNN\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path, custom_objects={\"FasterRCNN\": FasterRCNN}\n",
    ")\n",
    "\n",
    "# Each element of the `tiles` tensorflow Dataset is a (rgb_image_data, dictionary_of_annotation) pair.\n",
    "# Wrap the unwrapped_model so that it knows to use the image.\n",
    "class WrappedModel(tf.keras.Model):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super(WrappedModel, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, element):\n",
    "        return (self.model(element[0]), element[1])\n",
    "\n",
    "\n",
    "unwrapped_model = model\n",
    "model = WrappedModel(unwrapped_model)\n",
    "print(\"Model built and wrapped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35f6ac",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d330f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starting predictions\")\n",
    "start_time = time.time()\n",
    "# This model assumes that the tiles are not batched.  Do not use, e.g., tiles.batch(32).\n",
    "predictions = model.predict(tiles)\n",
    "end_time = time.time()\n",
    "number_of_inputs = len([0 for tile in tiles])\n",
    "number_of_predictions = predictions[0].shape[0]\n",
    "print(\n",
    "    f\"Made {number_of_predictions} predictions for {number_of_inputs} tiles in {end_time - start_time} s.\"\n",
    ")\n",
    "print(f\"Average of {(end_time - start_time) / number_of_inputs} s per tile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75925b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
