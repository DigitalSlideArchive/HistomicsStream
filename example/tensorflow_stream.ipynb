{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c50c61",
   "metadata": {},
   "source": [
    "# Demonstration of histomics_stream\n",
    "\n",
    "Click to open in [[GitHub](https://github.com/DigitalSlideArchive/HistomicsStream/tree/master/example/tensorflow_stream.ipynb)] [[Google Colab](https://colab.research.google.com/github/DigitalSlideArchive/HistomicsStream/blob/master/example/tensorflow_stream.ipynb)]\n",
    "\n",
    "The `histomics_stream` Python package sits at the start of any machine learning workflow that is built on the TensorFlow machine learning library.  The package is responsible for efficient access to the input image data that will be used to fit a new machine learning model or will be used to predict regions of interest in novel inputs using an already learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f22613",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you are running this notebook on Google Colab or another system where `histomics_stream` and its dependencies are not yet installed then they can be installed with the following commands.  Note that image readers in addition to openslide are also supported by using, e.g., `large_image[openslide,ometiff,openjpeg,bioformats]` on the below pip install command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get histomics_stream and its dependencies\n",
    "!apt update\n",
    "!apt install -y python3-openslide openslide-tools\n",
    "!pip install 'large_image[openslide]' --find-links https://girder.github.io/large_image_wheels\n",
    "!pip install histomics_stream\n",
    "\n",
    "# Get other packages used in this notebook\n",
    "# N.B. itkwidgets works with jupyter<=3.0.0\n",
    "!apt install libcudnn8 libcudnn8-dev\n",
    "!pip install histomics_detect pooch itkwidgets\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-matplotlib jupyterlab-datawidgets itkwidgets\n",
    "\n",
    "print(\n",
    "    \"\\nNOTE!: On Google Colab you may need to choose 'Runtime->Restart runtime' for these updates to take effect.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b1fd0",
   "metadata": {},
   "source": [
    "## Fetching and creating the test data\n",
    "This notebook has demonstrations that use the files `TCGA-AN-A0G0-01Z-00-DX1.svs` (365 MB) and `TCGA-AN-A0G0-01Z-00-DX1.mask.png` (4 kB),  The pooch commands will fetch them if they are not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9784b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://northwestern.box.com/shared/static/qelyzb45bigg6sqyumtj8kt2vwxztpzm' to file '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs'.\n",
      "Downloading data from 'https://northwestern.box.com/shared/static/2q13q2r83avqjz9glrpt3s3nop6uhi2i' to file '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.mask.png'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have /root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs\n",
      "Have /root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.mask.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pooch\n",
    "\n",
    "# download whole slide image\n",
    "wsi_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.svs\",\n",
    "    url=\"https://northwestern.box.com/shared/static/qelyzb45bigg6sqyumtj8kt2vwxztpzm\",\n",
    "    known_hash=\"d046f952759ff6987374786768fc588740eef1e54e4e295a684f3bd356c8528f\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {wsi_path}\")\n",
    "\n",
    "# download binary mask image\n",
    "mask_path = pooch.retrieve(\n",
    "    fname=\"TCGA-AN-A0G0-01Z-00-DX1.mask.png\",\n",
    "    url=\"https://northwestern.box.com/shared/static/2q13q2r83avqjz9glrpt3s3nop6uhi2i\",\n",
    "    known_hash=\"bb657ead9fd3b8284db6ecc1ca8a1efa57a0e9fd73d2ea63ce6053fbd3d65171\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"wsi\",\n",
    ")\n",
    "print(f\"Have {mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4179b8",
   "metadata": {},
   "source": [
    "## Creating a study for use with histomics_stream\n",
    "\n",
    "We describe the input and desired parameters using standard Python lists and dictionaries.  Here we give a high-level configuration; selection of tiles is done subsequently.\n",
    "\n",
    "N.B.: __*all*__ values that are number of pixels are based upon the `target_magnification` that is supplied to `FindResolutionForSlide`.  This includes pixel sizes of a slide, chunk, or tile and it includes the pixel coordinates for a chunk or tile.  It applies whether the numbers are supplied to histomics_stream or returned by histomics_stream.  However, if the `magnification_source` is not `exact` the `returned_magnification` may not equal the `target_magnification`; to get the number of pixels that is relevant for the `returned_magnification`, typically these numbers of pixels are multiplied by the ratio `returned_magnification / target_magnification`.  In particular, the *pixel size of the returned tiles* will be the requested size times this ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00246460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using python for large_image caching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_study0 = {'version': 'version-1', 'number_pixel_rows_for_tile': 256, 'number_pixel_columns_for_tile': 256, 'slides': {'Slide_0': {'filename': '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs', 'slide_name': 'TCGA-AN-A0G0-01Z-00-DX1', 'slide_group': 'Group 3', 'number_pixel_rows_for_chunk': 2048, 'number_pixel_columns_for_chunk': 2048, 'target_magnification': 20.0, 'scan_magnification': 40.0, 'read_magnification': 40.0, 'returned_magnification': 40.0, 'level': 8, 'number_pixel_rows_for_slide': 20572, 'number_pixel_columns_for_slide': 27607}}}\n"
     ]
    }
   ],
   "source": [
    "import histomics_stream as hs\n",
    "import histomics_stream.tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a study and insert study-wide information\n",
    "my_study0 = {\"version\": \"version-1\"}\n",
    "my_study0[\"number_pixel_rows_for_tile\"] = 256\n",
    "my_study0[\"number_pixel_columns_for_tile\"] = 256\n",
    "my_slides = my_study0[\"slides\"] = {}\n",
    "\n",
    "# Add a slide to the study, including slide-wide information with it.\n",
    "my_slide0 = my_slides[\"Slide_0\"] = {}\n",
    "my_slide0[\"filename\"] = wsi_path\n",
    "my_slide0[\"slide_name\"] = \"TCGA-AN-A0G0-01Z-00-DX1\"\n",
    "my_slide0[\"slide_group\"] = \"Group 3\"\n",
    "my_slide0[\"number_pixel_rows_for_chunk\"] = 2048\n",
    "my_slide0[\"number_pixel_columns_for_chunk\"] = 2048\n",
    "\n",
    "# For each slide, find the appropriate resolution given the target_magnification and\n",
    "# magnification_tolerance.  In this example, we use the same parameters for each slide,\n",
    "# but this is not required generally.\n",
    "find_resolution_for_slide = hs.configure.FindResolutionForSlide(\n",
    "    my_study0, target_magnification=20, magnification_source=\"native\"\n",
    ")\n",
    "for slide in my_study0[\"slides\"].values():\n",
    "    find_resolution_for_slide(slide)\n",
    "print(f\"my_study0 = {my_study0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18bd4e",
   "metadata": {},
   "source": [
    "## Tile selection\n",
    "\n",
    "We are going to demonstrate several approaches to choosing tiles.  Each approach will start with its own copy of the `my_study0` that we have built so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4e5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e2d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_study_tiles_by_grid = {'version': 'version-1', 'number_pixel_rows_for_tile': 256, 'number_pixel_columns_for_tile': 256, 'slides': {'Slide_0': {'filename': '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs', 'slide_name': 'TCGA-AN-A0G0-01Z-00-DX1', 'slide_group': 'Group 3', 'number_pixel_rows_for_chunk': 2048, 'number_pixel_columns_for_chunk': 2048, 'target_magnification': 20.0, 'scan_magnification': 40.0, 'read_magnification': 40.0, 'returned_magnification': 40.0, 'level': 8, 'number_pixel_rows_for_slide': 20572, 'number_pixel_columns_for_slide': 27607, 'number_tile_rows_for_slide': 91, 'number_tile_columns_for_slide': 123, 'tiles': {'tile_2912': {'tile_top': 5152, 'tile_left': 18592}, 'tile_6396': {'tile_top': 11648, 'tile_left': 0}, 'tile_6517': {'tile_top': 11648, 'tile_left': 27104}, 'tile_10782': {'tile_top': 19488, 'tile_left': 18144}, 'tile_10876': {'tile_top': 19712, 'tile_left': 11648}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate TilesByGridAndMask without a mask\n",
    "my_study_tiles_by_grid = copy.deepcopy(my_study0)\n",
    "tiles_by_grid = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid,\n",
    "    number_pixel_overlap_rows_for_tile=32,\n",
    "    number_pixel_overlap_columns_for_tile=32,\n",
    "    randomly_select=5,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid[\"slides\"].values():\n",
    "    tiles_by_grid(slide)\n",
    "print(f\"my_study_tiles_by_grid = {my_study_tiles_by_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018d44a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_study_tiles_by_grid_and_mask = {'version': 'version-1', 'number_pixel_rows_for_tile': 256, 'number_pixel_columns_for_tile': 256, 'slides': {'Slide_0': {'filename': '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs', 'slide_name': 'TCGA-AN-A0G0-01Z-00-DX1', 'slide_group': 'Group 3', 'number_pixel_rows_for_chunk': 2048, 'number_pixel_columns_for_chunk': 2048, 'target_magnification': 20.0, 'scan_magnification': 40.0, 'read_magnification': 40.0, 'returned_magnification': 40.0, 'level': 8, 'number_pixel_rows_for_slide': 20572, 'number_pixel_columns_for_slide': 27607, 'number_tile_rows_for_slide': 80, 'number_tile_columns_for_slide': 107, 'number_pixel_rows_for_mask': 642, 'number_pixel_columns_for_mask': 862, 'tiles': {'tile_298': {'tile_top': 512, 'tile_left': 21504}, 'tile_2758': {'tile_top': 6400, 'tile_left': 21248}, 'tile_3693': {'tile_top': 8704, 'tile_left': 14080}, 'tile_4256': {'tile_top': 9984, 'tile_left': 21248}, 'tile_4431': {'tile_top': 10496, 'tile_left': 11264}, 'tile_4672': {'tile_top': 11008, 'tile_left': 18176}, 'tile_4865': {'tile_top': 11520, 'tile_left': 12800}, 'tile_5220': {'tile_top': 12288, 'tile_left': 21504}, 'tile_6353': {'tile_top': 15104, 'tile_left': 10240}, 'tile_6930': {'tile_top': 16384, 'tile_left': 20992}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_tiles_by_grid_and_mask = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_tiles_by_grid_and_mask,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    randomly_select=10,\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_grid_and_mask[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(f\"my_study_tiles_by_grid_and_mask = {my_study_tiles_by_grid_and_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91970864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_study_tiles_by_list = {'version': 'version-1', 'number_pixel_rows_for_tile': 256, 'number_pixel_columns_for_tile': 256, 'slides': {'Slide_0': {'filename': '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs', 'slide_name': 'TCGA-AN-A0G0-01Z-00-DX1', 'slide_group': 'Group 3', 'number_pixel_rows_for_chunk': 2048, 'number_pixel_columns_for_chunk': 2048, 'target_magnification': 20.0, 'scan_magnification': 40.0, 'read_magnification': 40.0, 'returned_magnification': 40.0, 'level': 8, 'number_pixel_rows_for_slide': 20572, 'number_pixel_columns_for_slide': 27607, 'tiles': {'tile_2912': {'tile_top': 5152, 'tile_left': 18592}, 'tile_6396': {'tile_top': 11648, 'tile_left': 0}, 'tile_6517': {'tile_top': 11648, 'tile_left': 27104}, 'tile_10782': {'tile_top': 19488, 'tile_left': 18144}, 'tile_10876': {'tile_top': 19712, 'tile_left': 11648}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate TilesByList\n",
    "my_study_tiles_by_list = copy.deepcopy(my_study0)\n",
    "tiles_by_list = hs.configure.TilesByList(\n",
    "    my_study_tiles_by_list,\n",
    "    randomly_select=5,\n",
    "    tiles_dictionary=my_study_tiles_by_grid[\"slides\"][\"Slide_0\"][\"tiles\"],\n",
    ")\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_by_list[\"slides\"].values():\n",
    "    tiles_by_list(slide)\n",
    "print(f\"my_study_tiles_by_list = {my_study_tiles_by_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e120014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_study_tiles_randomly = {'version': 'version-1', 'number_pixel_rows_for_tile': 256, 'number_pixel_columns_for_tile': 256, 'slides': {'Slide_0': {'filename': '/root/.cache/pooch/wsi/TCGA-AN-A0G0-01Z-00-DX1.svs', 'slide_name': 'TCGA-AN-A0G0-01Z-00-DX1', 'slide_group': 'Group 3', 'number_pixel_rows_for_chunk': 2048, 'number_pixel_columns_for_chunk': 2048, 'target_magnification': 20.0, 'scan_magnification': 40.0, 'read_magnification': 40.0, 'returned_magnification': 40.0, 'level': 8, 'number_pixel_rows_for_slide': 20572, 'number_pixel_columns_for_slide': 27607, 'tiles': {'tile_0': {'tile_top': 4641, 'tile_left': 5282}, 'tile_1': {'tile_top': 598, 'tile_left': 12915}, 'tile_2': {'tile_top': 18388, 'tile_left': 21249}, 'tile_3': {'tile_top': 13223, 'tile_left': 19118}, 'tile_4': {'tile_top': 13723, 'tile_left': 16106}, 'tile_5': {'tile_top': 5966, 'tile_left': 9924}, 'tile_6': {'tile_top': 6321, 'tile_left': 18795}, 'tile_7': {'tile_top': 14803, 'tile_left': 13870}, 'tile_8': {'tile_top': 15574, 'tile_left': 21991}, 'tile_9': {'tile_top': 9431, 'tile_left': 24373}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate TilesRandomly\n",
    "my_study_tiles_randomly = copy.deepcopy(my_study0)\n",
    "tiles_randomly = hs.configure.TilesRandomly(my_study_tiles_randomly, randomly_select=10)\n",
    "# We could apply this to a subset of the slides, but we will apply it to all slides in\n",
    "# this example.\n",
    "for slide in my_study_tiles_randomly[\"slides\"].values():\n",
    "    tiles_randomly(slide)\n",
    "print(f\"my_study_tiles_randomly = {my_study_tiles_randomly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bcb07",
   "metadata": {},
   "source": [
    "## Creating a TensorFlow Dataset\n",
    "\n",
    "We request tiles indicated by the mask and create a tensorflow Dataset that has the image data for these tiles as well as associated parameters for each tile, such as its location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6618f2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished selecting tiles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:24:41.817040: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 18:24:42.505833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:db:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with CreateTensorFlowDataset\n",
      "... with tile shape = (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate TilesByGridAndMask with a mask\n",
    "my_study_of_tiles = copy.deepcopy(my_study0)\n",
    "tiles_by_grid_and_mask = hs.configure.TilesByGridAndMask(\n",
    "    my_study_of_tiles,\n",
    "    number_pixel_overlap_rows_for_tile=0,\n",
    "    number_pixel_overlap_columns_for_tile=0,\n",
    "    mask_filename=mask_path,\n",
    "    mask_threshold=0.5,\n",
    "    randomly_select=100,\n",
    ")\n",
    "for slide in my_study_of_tiles[\"slides\"].values():\n",
    "    tiles_by_grid_and_mask(slide)\n",
    "print(\"Finished selecting tiles.\")\n",
    "\n",
    "create_tensorflow_dataset = hs.tensorflow.CreateTensorFlowDataset()\n",
    "tiles = create_tensorflow_dataset(my_study_of_tiles)\n",
    "print(\"Finished with CreateTensorFlowDataset\")\n",
    "print(f\"... with tile shape = {tiles.take(1).get_single_element()[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72421b0a",
   "metadata": {},
   "source": [
    "## Fetch a model for prediction\n",
    "\n",
    "We fetch a model (840 MB compressed, 1.3 GB decompressed) that we will use to make predictions.\n",
    "\n",
    "Because each element of our Dataset is a tuple `(rgb_image_data, dictionary_of_annotation)`, a typical model that accepts only the former as its input needs to be wrapped.\n",
    "\n",
    "Note that this model assumes that the tiles/images are not batched, with the understanding that if there is enough memory to do batching then one should instead choose a larger tile size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbf1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://northwestern.box.com/shared/static/4g6idrqlpvgxnsktz8pym5386njyvyb6' to file '/root/.cache/pooch/model/tcga_brca_model'.\n",
      "Unzipping contents of '/root/.cache/pooch/model/tcga_brca_model' to '/root/.cache/pooch/model/tcga_brca_model.unzip'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have /root/.cache/pooch/model/tcga_brca_model.unzip/tcga_brca_model.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 2s 0us/step\n",
      "94683136/94668760 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 18:25:24.536937: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-04-26 18:25:36.339473: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'gradients/PartitionedCall_6_grad/PartitionedCall' has 3 outputs but the _output_shapes attribute specifies shapes for 33 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:36.339574: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'gradients/PartitionedCall_4_grad/PartitionedCall' has 3 outputs but the _output_shapes attribute specifies shapes for 33 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:36.339629: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'gradients/PartitionedCall_5_grad/PartitionedCall' has 3 outputs but the _output_shapes attribute specifies shapes for 33 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:36.339665: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'gradients/PartitionedCall_2_grad/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 6 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:36.339697: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'gradients/PartitionedCall_3_grad/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 6 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:39.837166: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'PartitionedCall_2' has 2 outputs but the _output_shapes attribute specifies shapes for 6 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:39.837258: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'PartitionedCall_3' has 2 outputs but the _output_shapes attribute specifies shapes for 6 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:39.837291: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'PartitionedCall_4' has 1 outputs but the _output_shapes attribute specifies shapes for 11 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:39.837348: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'PartitionedCall_5' has 1 outputs but the _output_shapes attribute specifies shapes for 11 outputs. Output shapes may be inaccurate.\n",
      "2022-04-26 18:25:39.837383: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'PartitionedCall_6' has 1 outputs but the _output_shapes attribute specifies shapes for 11 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built and wrapped.\n"
     ]
    }
   ],
   "source": [
    "# download trained model.\n",
    "model_path = pooch.retrieve(\n",
    "    fname=\"tcga_brca_model\",\n",
    "    url=\"https://northwestern.box.com/shared/static/4g6idrqlpvgxnsktz8pym5386njyvyb6\",\n",
    "    known_hash=\"b5b5444cc8874d17811a89261abeafd9b9603e7891a8b2a98d8f13e2846a6689\",\n",
    "    path=str(pooch.os_cache(\"pooch\")) + os.sep + \"model\",\n",
    "    processor=pooch.Unzip(),\n",
    ")\n",
    "model_path = os.path.split(model_path[0])[0]\n",
    "print(f\"Have {model_path}.\")\n",
    "\n",
    "# restore keras model\n",
    "from histomics_detect.models import FasterRCNN\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path, custom_objects={\"FasterRCNN\": FasterRCNN}\n",
    ")\n",
    "\n",
    "# Each element of the `tiles` tensorflow Dataset is a (rgb_image_data, dictionary_of_annotation) pair.\n",
    "# Wrap the unwrapped_model so that it knows to use the image.\n",
    "class WrappedModel(tf.keras.Model):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super(WrappedModel, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, element):\n",
    "        return (self.model(element[0]), element[1])\n",
    "\n",
    "\n",
    "unwrapped_model = model\n",
    "model = WrappedModel(unwrapped_model)\n",
    "print(\"Model built and wrapped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614c2a3",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b050a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predictions\n",
      "Made 8168 predictions for 100 tiles in 12.364816904067993 s.\n",
      "Average of 0.12364816904067993 s per tile.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starting predictions\")\n",
    "start_time = time.time()\n",
    "# This model assumes that the tiles are not batched.  Do not use, e.g., tiles.batch(32).\n",
    "predictions = model.predict(tiles)\n",
    "end_time = time.time()\n",
    "number_of_inputs = len([0 for tile in tiles])\n",
    "number_of_predictions = predictions[0].shape[0]\n",
    "print(\n",
    "    f\"Made {number_of_predictions} predictions for {number_of_inputs} tiles in {end_time - start_time} s.\"\n",
    ")\n",
    "print(f\"Average of {(end_time - start_time) / number_of_inputs} s per tile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc739b",
   "metadata": {},
   "source": [
    "## Look at internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1144f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type(my_element) = <class 'tuple'>\n",
      "    len(my_element) = 3\n",
      "      type(my_pair) = <class 'tuple'>\n",
      "       len(my_pair) = 2\n",
      "    type(my_target) = <class 'NoneType'>\n",
      "    type(my_weight) = <class 'NoneType'>\n",
      "     type(my_image) = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "     my_image.shape = (512, 512, 3)\n",
      "type(my_annotation) = <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "my_element = tiles.take(1).get_single_element()\n",
    "my_pair = my_element[0]\n",
    "my_target = my_element[1]\n",
    "my_weight = my_element[2]\n",
    "my_image = my_pair[0]\n",
    "my_annotation = my_pair[1]\n",
    "\n",
    "print(f\"   type(my_element) = {type(my_element)}\")\n",
    "print(f\"    len(my_element) = {len(my_element)}\")\n",
    "print(f\"      type(my_pair) = {type(my_pair)}\")\n",
    "print(f\"       len(my_pair) = {len(my_pair)}\")\n",
    "print(f\"    type(my_target) = {type(my_target)}\")\n",
    "print(f\"    type(my_weight) = {type(my_weight)}\")\n",
    "print(f\"     type(my_image) = {type(my_image)}\")\n",
    "print(f\"     my_image.shape = {my_image.shape}\")\n",
    "print(f\"type(my_annotation) = {type(my_annotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d492e513",
   "metadata": {},
   "source": [
    "## Display a tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9531e48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488d59d05f994efebaf3bc464a97150a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageRGBUC2;…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itk, itkwidgets\n",
    "\n",
    "itkwidgets.view(itk.image_from_array(my_image.numpy(), is_vector=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
