{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update -y\n",
    "!apt-get install python3-openslide -y\n",
    "!pip install openslide-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import openslide as os\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_field(element, field, value):\n",
    "  #Assigns value to field of dict element. This is a wrapper used for assignment\n",
    "  #of fields in dict dataset elements since the lambda functions used with \n",
    "  #tf.data.Dataset.map cannot perform assignments.\n",
    "  #Typical usage Dataset.map(lambda element: assign_field(element, 'tiles', \n",
    "  #imresize(element['tiles'])))\n",
    "  element[field] = value\n",
    "  return element\n",
    "\n",
    "\n",
    "def _add_fields(element, fields, values):\n",
    "  #Add fields to struct. Use with tf.data.Dataset.map. Operates in-place.\n",
    "  for field, value in zip(fields, values):\n",
    "    element[field] = value\n",
    "  return element\n",
    "\n",
    "\n",
    "def _expand_tensors(element, fields, reference):\n",
    "  #Expands tensor fields in dataset element to match the length of a reference \n",
    "  #field. This allows application of tf.data.Dataset.flat_map to expand from\n",
    "  #a read-chunk element dataset to a tile dataset using from_tensor_slices.\n",
    "\n",
    "  #get reference field length\n",
    "  length = tf.size(element[reference])\n",
    "\n",
    "  #iterate over fields removing singleton dimensions and repeating\n",
    "  for field in fields:\n",
    "    if tf.is_tensor(element[field]):\n",
    "      element[field] = tf.repeat(tf.squeeze(element[field]), length)\n",
    "\n",
    "    else: #raise exception - assume all fields are tensor type\n",
    "      raise ValueError('Field is not tensor.')\n",
    "\n",
    "  return element\n",
    "\n",
    "\n",
    "def _tile_coords(width, height, tw, th, ow, oh):\n",
    "#generates tiling coordinates for reading (th, tw) tiles with (ox, oy) overlap \n",
    "#from a (height, width) image.\n",
    "#For example, if image with `width` fits exactly `N` tiles with width `tw` and overlap `ow` then\n",
    "#  width == N * (tw-ow) + ow,\n",
    "#otherwise the tiles farthest to the right will not be of full width `tw`.  We omit these defective tiles.\n",
    "#... and similarly for heights instead of widths.\n",
    "\n",
    "  #Generate list of read coordinates\n",
    "  left = tf.range(0, width-tw+1, tw-ow)\n",
    "  right = tf.clip_by_value(left+tw, 0, width)\n",
    "  top = tf.range(0, height-th+1, th-oh)\n",
    "  bottom = tf.clip_by_value(top+th, 0, height)\n",
    "  l = tf.repeat(left, tf.size(top))\n",
    "  w = tf.repeat(right-left, tf.size(top))\n",
    "  t = tf.tile(top, tf.stack([tf.size(left)]))\n",
    "  h = tf.tile(bottom-top, tf.stack([tf.size(left)]))\n",
    "\n",
    "  return l, t, w, h\n",
    "\n",
    "\n",
    "def _add_tile_coords_fields(element, tile, overlap):\n",
    "    tx, ty, tw, th = _tile_coords(element['cw'], element['ch'], tile[0], tile[1], overlap[0], overlap[1])\n",
    "    _add_fields(element, ['tx', 'ty', 'tw', 'th', 'ow', 'oh'], [tx, ty, tw, th, overlap[0], overlap[1]])\n",
    "    return element\n",
    "\n",
    "\n",
    "def get_read_parameters(filename, magnification, tolerance = 1e-2):\n",
    "\n",
    "  #read whole-slide image file and create openslide object\n",
    "  os_obj = os.OpenSlide(filename)\n",
    "\n",
    "  #measure objective of level 0\n",
    "  objective = np.float32(os_obj.properties[os.PROPERTY_NAME_OBJECTIVE_POWER])\n",
    "\n",
    "  #calculate magnifications of levels\n",
    "  estimated = np.array(objective / os_obj.level_downsamples)\n",
    "\n",
    "  #calculate difference with magnification levels\n",
    "  delta = magnification - estimated\n",
    "\n",
    "  #match to existing levels\n",
    "  if np.min(np.abs(np.divide(delta, magnification))) < tolerance: #match\n",
    "    level = np.squeeze(np.argmin(np.abs(delta)))\n",
    "    factor = 1.0\n",
    "  elif np.any(delta < 0):\n",
    "    value = np.max(delta[delta < 0])\n",
    "    level = np.squeeze(np.argwhere(delta == value)[0])\n",
    "    factor = magnification / estimated[level]\n",
    "  else: #desired magnification above base level - throw error\n",
    "    raise ValueError('Cannot interpolate above scan magnification.')\n",
    "\n",
    "  #get slide width, height at desired magnification\n",
    "  width, height = os_obj.level_dimensions[level]\n",
    "\n",
    "  return level, factor, width, height\n",
    "\n",
    "\n",
    "def read_region(filename, level, x, y, w, h):\n",
    "\n",
    "  #open slide\n",
    "  os_obj = os.OpenSlide(filename.numpy())\n",
    "\n",
    "  #read chunk and convert to tensor\n",
    "  chunk = os_obj.read_region((x.numpy(), y.numpy()),\n",
    "                             level.numpy(),\n",
    "                             (w.numpy(), h.numpy()))\n",
    "\n",
    "  return tf.convert_to_tensor(np.array(chunk)[...,:3], dtype=tf.uint8) \n",
    "\n",
    "\n",
    "def tf_read_region(filename, level, x, y, w, h):\n",
    "  return tf.py_function(func=read_region, \n",
    "                        inp=[filename, level, x, y, w, h], \n",
    "                        Tout=tf.uint8)\n",
    "\n",
    "\n",
    "def _read_chunk(element):\n",
    "\n",
    "  #read chunk and convert to tensor\n",
    "  chunk = tf_read_region(element['filename'],\n",
    "                         tf.cast(element['level'], dtype=tf.uint32),\n",
    "                         element['cx'], element['cy'],\n",
    "                         element['cw'], element['ch'])\n",
    "\n",
    "  #split read chunk into tiles using a loop.\n",
    "  #this avoids copying 'chunk' with 'map_fn' or 'tf.image.generate_glimpse'\n",
    "  tiles = tf.TensorArray(dtype=tf.uint8, size=tf.size(element['tx']))\n",
    "  condition = lambda i, _: tf.less(i, tf.size(element['tx']))\n",
    "  body = lambda i, tiles: (i+1, \n",
    "                           tiles.write(i, tf.image.crop_to_bounding_box(chunk,\n",
    "                                                        tf.gather(element['ty'], i),\n",
    "                                                        tf.gather(element['tx'], i),\n",
    "                                                        tf.gather(element['th'], i),\n",
    "                                                        tf.gather(element['tw'], i))))\n",
    "  _, tiles = tf.while_loop(condition, body, [0, tiles])  \n",
    "  tiles = tiles.stack()\n",
    "\n",
    "  #add tile tensor to element\n",
    "  element['tiles'] = tiles\n",
    "\n",
    "  #return dataset element dict\n",
    "  return element\n",
    "\n",
    "def _merge_dist_tensor(distributed, axis=0):\n",
    "    #check if input is type roduced by distributed.Strategy.run\n",
    "    if isinstance(distributed, tf.python.distribute.values.PerReplica):\n",
    "        return tf.concat(strategy.experimental_local_results(distributed), axis=axis)\n",
    "    else:\n",
    "        raise ValueError('Input to _merge_dist_tensor not a distributed PerReplica tensor.')\n",
    "\n",
    "\n",
    "def _merge_dist_dict(distributed, axis=0):\n",
    "    #check if input is type roduced by distributed.Strategy.run\n",
    "    if isinstance(distributed, dict):\n",
    "        for key in distributed.keys():\n",
    "            distributed[key] = _merge_dist_tensor(distributed[key], axis=axis)\n",
    "        return distributed\n",
    "    else:\n",
    "        raise ValueError('Input to _merge_dist_tensor not a dict.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiled(filename, slide='', case='', magnification=20.0, tile=(256, 256), \n",
    "          overlap=(0, 0), chunkFactor=(4, 4), mask=None):\n",
    "  \"\"\"Generates a tf.data.Dataset where each element contains RGB pixel data \n",
    "  generated by a regular-grid tiling of the slide. This function generates an \n",
    "  intermediate dataset of \"read chunks\" that contain many tiles, and that\n",
    "  defines the actual reads made from the whole-slide image file. Functions are\n",
    "  applied to tile these reads and stack them into a new dataset containing the\n",
    "  tiles. This function is used to stream tiles to downstream preprocessing, \n",
    "  inference, or training steps to hide read times with these compute-intensive \n",
    "  operations.\n",
    "\n",
    "  Related functions enable these tiles to be filtered and grouped by read chunk,\n",
    "  slide, or case to enable complex logic for controlling downstream operations\n",
    "  and for aggregating and organizing their outputs.\n",
    "\n",
    "  Each element in the tile dataset is a dict where the tile is stored in \n",
    "  element['tiles']. Metadata stored in other fields includes:\n",
    "\n",
    "    slide - name of slide without file extension\n",
    "    filename - filename and path of whole-slide image file.\n",
    "    case - string describing case that slide is associated with.\n",
    "    magnification - float describing objective magnification of tiles.\n",
    "    cx, cy - location of upper-left corner of read chunk in pixels at native \n",
    "      scan magnification. Used for calculating global coordinates.\n",
    "    cw, ch - parameter width and height of read chunk in pixels.\n",
    "    level - read level used to access pixel data from file.\n",
    "    factor - resizing factor applied to read chunk images read from `level`. If\n",
    "      < 1 then `magnification` is not available in the file and must be computed\n",
    "      from a high magnification.\n",
    "    tw, th - parameter tile width and height in pixels.\n",
    "    tx, ty - local coordates of tile in read chunk.\n",
    "    ow, oh - parameter overlap width and height in pixels.\n",
    "    read_mode - string containing.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename: string\n",
    "    Path and filename of the slide readable by openslide.\n",
    "  slide: string\n",
    "    Slide name (used for operations that gather tiles by slide). Default ''.\n",
    "  case: string\n",
    "    Case identifier (used for gather operations on tiles). Default ''.\n",
    "  magnification: float\n",
    "    Desired objective magnification of pixel data tiles extracted from \n",
    "    `filename`. Default 20.0.\n",
    "  tile: (int, int)\n",
    "    Tuple containing width and height respectively of extracted tiles. Default\n",
    "    (256, 256).\n",
    "  overlap: (int, int)\n",
    "    Tuple containing horizontal and vertical overlap of tiles. Default (0, 0).\n",
    "  chunkFactor: (int, int)\n",
    "    Number of overlapping tiles that fit in a chunk in each direction. Critical for performance.\n",
    "    These chunks are tiled and the tiles stacked to generate the output dataset. \n",
    "    Default (4, 4).\n",
    "  mask: array_like\n",
    "    Boolean mask of slide indicating where tiles should be extracted. Acceptable \n",
    "    types include _____.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  tiled: tf.data.Dataset\n",
    "    A dataset where each element contains an tuple of (RGB tile, metadata). The\n",
    "    tile and metadata are separated in the tuple to satisfy unpacking rules.\n",
    "    \n",
    "  See Also\n",
    "  --------\n",
    "  dense: A function for generating tiles at arbitrary locations from a single \n",
    "    read.\n",
    "  \"\"\"\n",
    "\n",
    "  level, factor, width, height = get_read_parameters(filename, magnification)\n",
    "\n",
    "  #**** error if magnification > native ****\n",
    "\n",
    "  chunk = (overlap[0] + chunkFactor[0] * (tile[0] - overlap[0]), overlap[1] + chunkFactor[1] * (tile[1] - overlap[1])) \n",
    "  #generate list of read coordinates (global frame, upper-left corner)\n",
    "  cx, cy, cw, ch = _tile_coords(width, height, \n",
    "                        chunk[0], chunk[1], \n",
    "                        overlap[0], overlap[1])\n",
    "\n",
    "  #generate read chunk dataset\n",
    "  read = tf.data.Dataset.from_tensor_slices({'cx': cx, 'cy': cy, 'cw': cw, 'ch': ch})\n",
    "\n",
    "  #add general parameters\n",
    "  read = read.map(lambda elem: _add_fields(elem, ['slide', 'case', 'filename',\n",
    "                                                  'magnification', 'read_mode'],\n",
    "                                          [slide, case, filename,\n",
    "                                           magnification, 'tiled']),\n",
    "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  #add chunk parameters\n",
    "  read = read.map(lambda elem: \n",
    "                  _add_fields(elem, ['level', 'factor'],\n",
    "                              [level, 1.0]),\n",
    "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  #**** error if mismatch between tile size and read chunk size ****\n",
    "\n",
    "  #generate list of tile coordinates (local frame, upper-left corner)\n",
    "  read = read.map(lambda elem:\n",
    "                  _add_tile_coords_fields(elem, tile, overlap),\n",
    "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  #apply this function to the read chunk dataset\n",
    "  read = read.map(_read_chunk, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  #expand dimensions to match number of tiles\n",
    "  read = read.map(lambda element: \n",
    "                  _expand_tensors(element, ['slide', 'filename', 'case',\n",
    "                                            'magnification', 'cx', 'cy', \n",
    "                                            'cw', 'ch', 'level', 'factor',\n",
    "                                            'ow', 'oh', \n",
    "                                            'read_mode'], 'tx'),\n",
    "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  \n",
    "  #flatten dataset to make each element one tile\n",
    "  tiled = read.flat_map(lambda element:\n",
    "                        tf.data.Dataset.from_tensor_slices(element))\n",
    "  \n",
    "  #split tile, metadata into tuple\n",
    "  tiled = tiled.map(lambda element: (element.pop('tiles'), element))\n",
    "\n",
    "  return tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "#using numpy_function allows mapping of keras functions to dataset elements\n",
    "\n",
    "#set slide and read parameters\n",
    "filename='TCGA-BH-A0BZ-01Z-00-DX1.45EB3E93-A871-49C6-9EAE-90D98AE01913.svs'\n",
    "slide='TCGA-BH-A0BZ-01Z-00-DX1.45EB3E93-A871-49C6-9EAE-90D98AE01913'\n",
    "case='TCGA-BH-A0BZ'\n",
    "magnification=20.0\n",
    "tile=(tf.constant(256, dtype=tf.int32), \n",
    "      tf.constant(256, dtype=tf.int32))\n",
    "chunkFactor=(tf.constant(8, dtype=tf.int32),\n",
    "             tf.constant(8, dtype=tf.int32))\n",
    "overlap=(tf.constant(0, dtype=tf.int32),\n",
    "         tf.constant(0, dtype=tf.int32))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "devices=[gpu.name.replace(\"/physical_device:\", \"/\").lower() for gpu in tf.config.experimental.list_physical_devices('GPU')]\n",
    "batch_size = 128*len(devices)\n",
    "\n",
    "#define strategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=devices)\n",
    "\n",
    "#generate network model\n",
    "with strategy.scope():\n",
    "    model = tf.keras.applications.VGG16(include_top=True, weights='imagenet')\n",
    "    model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('fc1').output)\n",
    "\n",
    "#generate tiles dataset\n",
    "tiles = tiled(filename, slide, case, magnification, \n",
    "              tile, overlap, chunkFactor, mask=None)\n",
    "\n",
    "#batch tiles\n",
    "batched = tiles.batch(batch_size)\n",
    "\n",
    "#apply preprocessing to batched tiles - resize, float conversion, preprocessing\n",
    "batched = batched.map(lambda tile, metadata:\n",
    "                      (tf.cast(tf.image.resize(tile, [224, 224]), tf.float32),\n",
    "                       metadata), \n",
    "                      num_parallel_calls=AUTOTUNE)\n",
    "batched = batched.map(lambda tile, metadata:\n",
    "                      (tf.keras.applications.resnet_v2.preprocess_input(tile),\n",
    "                       metadata), \n",
    "                      num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "#set prefetch\n",
    "batched_dist = strategy.experimental_distribute_dataset(batched)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leenewberg/venv/jupyter/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "Distributed dataset: 212.294590\n"
     ]
    }
   ],
   "source": [
    "#wrap prediction function in graph\n",
    "@tf.function\n",
    "def predict(element):\n",
    "    return model(element[0]), element[1]\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "#distributed inference, condensing distributed feature tensors, metadata dicts in lists\n",
    "feature_list = []\n",
    "metadata_list = []\n",
    "for element in batched_dist:\n",
    "    f, meta = strategy.run(predict, args=(element,))\n",
    "    feature_list.append(_merge_dist_tensor(f))\n",
    "    metadata_list.append(_merge_dist_dict(meta))\n",
    "\n",
    "#merge features into single array    \n",
    "features = tf.concat(feature_list, axis=0)\n",
    "del feature_list\n",
    "\n",
    "#merge metadata into single dict\n",
    "metadata = {}\n",
    "for key in metadata_list[0].keys():\n",
    "    metadata[key] = tf.concat([meta[key] for meta in metadata_list], axis=0)\n",
    "del metadata_list\n",
    "\n",
    "#map tile coordinates from chunk frame to global slide frame\n",
    "metadata['tx'] = metadata['tx'] + metadata['cx']\n",
    "metadata['ty'] = metadata['ty'] + metadata['cy']\n",
    "\n",
    "print(\"Distributed dataset: %f\" % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing h5 data: 45.976658\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "#write features, metadata to disk\n",
    "with h5py.File('mytestfile.hdf5', 'w') as handle:\n",
    "    handle.create_dataset('slides', data=metadata['slide'].numpy(), \n",
    "                          dtype=h5py.string_dtype(encoding='ascii'))\n",
    "    handle.create_dataset('features', data=features.numpy(), dtype='float')\n",
    "    handle.create_dataset('slideIdx', data=np.zeros(metadata['slide'].shape), dtype='int')\n",
    "    handle.create_dataset('x_centroid', data=metadata['tx'].numpy(), dtype='float')\n",
    "    handle.create_dataset('y_centroid', data=metadata['ty'].numpy(), dtype='float')\n",
    "    handle.create_dataset('dataIdx', data=np.zeros(1), dtype='int')\n",
    "    handle.create_dataset('wsi_mean', data=np.zeros(3), dtype='float')\n",
    "    handle.create_dataset('wsi_std', data=np.zeros(3), dtype='float')\n",
    "        \n",
    "print(\"Writing h5 data: %f\" % (time.time() - tic))\n",
    "\n",
    "#write superpixel boundaries to disk\n",
    "tic = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
